~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mask shape -1 (340, 500)
mask shape (340, 500)
mask reshape (170000,)
C:\Users\admin\miniconda3\envs\hanna_py37_default\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
========================================== batch  0
output.shape torch.Size([170000, 100])
outputHP shape:  torch.Size([340, 500, 100])
HPy, HPz:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
HPy_target, HPz_target:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
im_target shape:  (170000,)
nLabels:  100
torch.Size([170000, 100])
torch.Size([170000])
torch.Size([170000])
output[inds_sim].shape:  torch.Size([164823, 100])
target[inds_sim].shape:  torch.Size([164823])
loss fn:  tensor(2.9288, device='cuda:0', grad_fn=<NllLossBackward0>)
loss_fn_scr fn:  tensor(2.9260, device='cuda:0', grad_fn=<NllLossBackward0>)

--- scribble 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mask shape -1 (340, 500, 3)
mask shape (340, 500)
mask reshape (170000,)
C:\Users\admin\miniconda3\envs\hanna_py37_default\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
========================================== batch  0
output.shape torch.Size([170000, 100])
outputHP shape:  torch.Size([340, 500, 100])
HPy, HPz:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
HPy_target, HPz_target:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
im_target shape:  (170000,)
nLabels:  100
torch.Size([170000, 100])
torch.Size([170000])
torch.Size([170000])
output[inds_sim].shape:  torch.Size([164641, 100])
target[inds_sim].shape:  torch.Size([164641])
loss fn:  tensor(2.9853, device='cuda:0', grad_fn=<NllLossBackward0>)
loss_fn_scr fn:  tensor(2.9997, device='cuda:0', grad_fn=<NllLossBackward0>)

--scribble1 (faulty)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mask shape -1 (326, 334, 4)
mask shape (326, 334)
mask reshape (108884,)
C:\Users\admin\miniconda3\envs\hanna_py37_default\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
========================================== batch  0
output.shape torch.Size([108884, 100])
outputHP shape:  torch.Size([326, 334, 100])
HPy, HPz:  torch.Size([325, 334, 100]) torch.Size([326, 333, 100])
HPy_target, HPz_target:  torch.Size([325, 334, 100]) torch.Size([326, 333, 100])
im_target shape:  (108884,)
nLabels:  93
torch.Size([108884, 100])
torch.Size([108884])
torch.Size([108884])
output[inds_sim].shape:  torch.Size([105646, 100])
target[inds_sim].shape:  torch.Size([105646])
loss fn:  tensor(3.3107, device='cuda:0', grad_fn=<NllLossBackward0>)
loss_fn_scr fn:  tensor(3.0965, device='cuda:0', grad_fn=<NllLossBackward0>)

-- test scribble (faulty)






























================================================================================

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mask shape -1 (340, 500)
mask shape (340, 500)
mask reshape (170000,)
C:\Users\admin\miniconda3\envs\hanna_py37_default\lib\site-packages\torch\nn\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
========================================== batch  0
output.shape torch.Size([170000, 100])
outputHP shape:  torch.Size([340, 500, 100])
HPy, HPz:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
HPy_target, HPz_target:  torch.Size([339, 500, 100]) torch.Size([340, 499, 100])
im_target shape:  (170000,)
nLabels:  100
output shape  torch.Size([170000, 100])
target shape  torch.Size([170000])
target_scr shape  torch.Size([170000])
output[inds_sim] tensor([[ 5.4055,  0.8187,  0.8142,  ...,  0.8776, -4.6224,  1.5007],
        [ 0.3124, -3.3261,  0.8704,  ...,  2.0955, -3.2109,  1.5976],
        [ 1.7393, -1.7268,  0.6886,  ...,  0.4464, -3.3484,  0.6004],
        ...,
        [ 2.0653,  2.0912, -2.0947,  ...,  3.4043,  0.3288,  2.6735],
        [ 2.9248,  0.2844, -0.4149,  ...,  5.4427, -0.3228,  6.6111],
        [ 5.3800, -0.5462, -0.9848,  ...,  0.6536, -1.2488,  3.7756]],
       device='cuda:0', grad_fn=<IndexBackward0>)
output[inds_scr] tensor([[-0.0092,  0.8979, -0.6193,  ...,  0.6691,  1.1462, -0.4173],
        [ 2.2187, -0.7298, -1.0182,  ...,  1.2694,  1.3716, -0.9957],
        [ 3.2433,  1.4349, -0.4172,  ...,  1.3725,  4.0812,  2.3409],
        ...,
        [-0.3878, -0.2246, -1.1340,  ...,  0.4237,  0.0098, -0.3148],
        [ 0.2557,  0.3095, -0.7994,  ...,  1.3735,  0.2807, -0.6589],
        [ 0.8632,  1.0409, -0.0116,  ...,  1.3977,  0.9435, -0.6878]],
       device='cuda:0', grad_fn=<IndexBackward0>)
target[inds_sim] tensor([60, 26, 72,  ..., 44, 62, 17], device='cuda:0')
target[inds_scr] tensor([71, 16, 19,  ..., 45, 35, 13], device='cuda:0')
target_scr[inds_sim] tensor([255, 255, 255,  ..., 255, 255, 255], device='cuda:0',
       dtype=torch.uint8)
target_scr[inds_scr] tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0', dtype=torch.uint8)
loss fn, inds_sim:  tensor(2.9715, device='cuda:0', grad_fn=<NllLossBackward0>)
loss fn, inds_scr target scr:  tensor(5.2354, device='cuda:0', grad_fn=<NllLossBackward0>)
scr loss
output[inds_scr].shape:  torch.Size([5177, 100])
target[inds_scr].shape:  torch.Size([5177])
target_scr[inds_scr].shape:  torch.Size([5177])
tensor(5.2354, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor(5.2354, device='cuda:0', grad_fn=<NllLossBackward0>)
tensor([ 22997,  22998,  22999,  ..., 158476, 158477, 158478], device='cuda:0')
0 / 1 |  label num : 100  | loss : 7.018883228302002


-- scribble